{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "NEW_VALIDATION_FORCE.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKzY0MX5EluI"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import numpy.random as nr\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "#!pip install catboost\n",
        "#from catboost import CatBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn import preprocessing\n",
        "import sklearn.model_selection as ms\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGdm8oP7Y2jI"
      },
      "source": [
        "def fill_missing_values(data):\n",
        "    \n",
        "    '''\n",
        "    Function to input missing values based on the column object type\n",
        "    '''\n",
        "    \n",
        "    cols = list(data.columns)\n",
        "    for col in cols:\n",
        "        if data[col].dtype == 'int64' or data[col].dtype == 'float64':\n",
        "        \n",
        "            data[col] = data[col].fillna(data[col].mean())\n",
        "        \n",
        "        #elif data[col].dtype == 'O' or data[col].dtype == 'object':\n",
        "        #    data[col] = data[col].fillna(data[col].mode()[0])\n",
        "            \n",
        "        else:\n",
        "            data[col] = data[col].fillna(data[col].mode()[0])\n",
        "            \n",
        "    return data\n",
        " \n",
        "def one_hot_encoding(traindata, *args):\n",
        "    \n",
        "    for ii in args:\n",
        "        traindata = pd.get_dummies(traindata, prefix=[ii], columns=[ii])\n",
        "        \n",
        "    return traindata\n",
        " \n",
        "def drop_columns(traindata, *args):\n",
        "    \n",
        "    #labels = np.array(traindata[target])\n",
        "    \n",
        "    columns = []\n",
        "    for _ in args:\n",
        "        columns.append(_)\n",
        "        \n",
        "    traindata = traindata.drop(columns, axis=1)\n",
        "    #traindata = traindata.drop(target, axis=1)\n",
        "    #testdata = testdata.drop(columns, axis=1)\n",
        "        \n",
        "    return traindata\n",
        " \n",
        "def process(traindata):\n",
        "    \n",
        "    cols = list(traindata.columns)\n",
        "    for _ in cols:\n",
        "        traindata[_] = np.where(traindata[_] == np.inf, -999, traindata[_])\n",
        "        traindata[_] = np.where(traindata[_] == np.nan, -999, traindata[_])\n",
        "        traindata[_] = np.where(traindata[_] == -np.inf, -999, traindata[_])\n",
        "        \n",
        "    return traindata\n",
        " \n",
        "def show_evaluation(pred, true):\n",
        "  print(f'Default score: {score(true.values, pred)}')\n",
        "  print(f'Accuracy is: {accuracy_score(true, pred)}')\n",
        "  print(f'F1 is: {f1_score(pred, true.values, average=\"weighted\")}')\n",
        " \n",
        "def freq_encode(data, cols):\n",
        "    for i in cols:\n",
        "        encoding = data.groupby(i).size()\n",
        "        encoding = encoding/len(data)\n",
        "        data[i + '_enc'] = data[i].map(encoding)\n",
        "    return data\n",
        " \n",
        " \n",
        "def mean_target(data, cols):\n",
        "    kf = StratifiedKFold(10, shuffle=False)\n",
        "    a = pd.DataFrame()\n",
        "    for tr_ind, val_ind in kf.split(data, data.FORCE_2020_LITHOFACIES_LITHOLOGY):\n",
        "        X_tr, X_val= data.iloc[tr_ind].copy(), data.iloc[val_ind].copy()\n",
        "        for col in cols:\n",
        "            means = X_val[col].map(X_tr.groupby(col).FORCE_2020_LITHOFACIES_LITHOLOGY.mean())\n",
        "            X_val[col + '_mean_target'] = means + 0.0001\n",
        "        a = pd.concat((a, X_val))\n",
        "    #prior = FORCE_2020_LITHOFACIES_LITHOLOGY.mean()\n",
        "    #a.fillna(prior, inplace=True)\n",
        "    return a\n",
        " \n",
        "def make_submission(prediction, filename):\n",
        " \n",
        "  path = '/content/drive/My Drive/FORCE-Lithology-Prediction/'\n",
        " \n",
        "  test = pd.read_csv('/content/drive/My Drive/FORCE-Lithology-Prediction/Test.csv', sep=';')\n",
        "  #test_prediction = model.predict(testdata)\n",
        " \n",
        "  #test_prediction\n",
        "  category_to_lithology = {y:x for x,y in lithology_numbers.items()}\n",
        "  test_prediction_for_submission = np.vectorize(category_to_lithology.get)(prediction)\n",
        "  np.savetxt(path+filename+'.csv', test_prediction_for_submission, header='lithology', fmt='%i')\n",
        " \n",
        "# Feature windows concatenation function\n",
        "def augment_features_window(X, N_neig):\n",
        "    \n",
        "    # Parameters\n",
        "    N_row = X.shape[0]\n",
        "    N_feat = X.shape[1]\n",
        " \n",
        "    # Zero padding\n",
        "    X = np.vstack((np.zeros((N_neig, N_feat)), X, (np.zeros((N_neig, N_feat)))))\n",
        " \n",
        "    # Loop over windows\n",
        "    X_aug = np.zeros((N_row, N_feat*(2*N_neig+1)))\n",
        "    for r in np.arange(N_row)+N_neig:\n",
        "        this_row = []\n",
        "        for c in np.arange(-N_neig,N_neig+1):\n",
        "            this_row = np.hstack((this_row, X[r+c]))\n",
        "        X_aug[r-N_neig] = this_row\n",
        " \n",
        "    return X_aug\n",
        " \n",
        "# Feature gradient computation function\n",
        "def augment_features_gradient(X, depth):\n",
        "    \n",
        "    # Compute features gradient\n",
        "    d_diff = np.diff(depth).reshape((-1, 1))\n",
        "    d_diff[d_diff==0] = 0.001\n",
        "    X_diff = np.diff(X, axis=0)\n",
        "    X_grad = X_diff / d_diff\n",
        "        \n",
        "    # Compensate for last missing value\n",
        "    X_grad = np.concatenate((X_grad, np.zeros((1, X_grad.shape[1]))))\n",
        "    \n",
        "    return X_grad\n",
        " \n",
        "# Feature augmentation function\n",
        "def augment_features(X, well, depth, N_neig=1):\n",
        "    \n",
        "    # Augment features\n",
        "    X_aug = np.zeros((X.shape[0], X.shape[1]*(N_neig*2+2)))\n",
        "    for w in np.unique(well):\n",
        "        w_idx = np.where(well == w)[0]\n",
        "        X_aug_win = augment_features_window(X[w_idx, :], N_neig)\n",
        "        X_aug_grad = augment_features_gradient(X[w_idx, :], depth[w_idx])\n",
        "        X_aug[w_idx, :] = np.concatenate((X_aug_win, X_aug_grad), axis=1)\n",
        "    \n",
        "    # Find padded rows\n",
        "    padded_rows = np.unique(np.where(X_aug[:, 0:7] == np.zeros((1, 7)))[0])\n",
        "    \n",
        "    return X_aug, padded_rows"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuul_30fY2-y"
      },
      "source": [
        "A = np.load('/content/drive/My Drive/FORCE-Lithology-Prediction/penalty_matrix.npy')\n",
        " \n",
        "def score(y_true, y_pred):\n",
        "    S = 0.0\n",
        "    y_true = y_true.astype(int)\n",
        "    y_pred = y_pred.astype(int)\n",
        "    for i in range(0, y_true.shape[0]):\n",
        "        S -= A[y_true[i], y_pred[i]]\n",
        "    return S/y_true.shape[0]\n",
        " \n",
        "def evaluate(model):\n",
        "    feat_imp = pd.Series(model.feature_importances_).sort_values(ascending=False)\n",
        "    plt.figure(figsize=(24,8))\n",
        "    feat_imp.plot(kind='bar', title=f'Feature Importances {len(model.feature_importances_)}')\n",
        "    plt.ylabel('Feature Importance Score')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6naYqmLn05D"
      },
      "source": [
        "#importing files\n",
        "train = pd.read_csv('/content/drive/My Drive/FORCE-Lithology-Prediction/train1.csv')\n",
        "test = pd.read_csv('/content/drive/My Drive/FORCE-Lithology-Prediction/Test.csv', sep=';')\n",
        "valid1 = pd.read_csv('/content/drive/My Drive/FORCE-Lithology-Prediction/valid4.csv')\n",
        "valid2 = pd.read_csv('/content/drive/My Drive/FORCE-Lithology-Prediction/valid5.csv')\n",
        "valid3 = pd.concat((valid1, valid2)).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tt79NastY5VW"
      },
      "source": [
        "ntrain = train.shape[0]\n",
        "ntest = test.shape[0]\n",
        "nvalid1 = valid1.shape[0]\n",
        "nvalid2 = valid2.shape[0]\n",
        "nvalid3 = valid3.shape[0]\n",
        "target = train.FORCE_2020_LITHOFACIES_LITHOLOGY.copy()\n",
        "df = pd.concat((train, test, valid1, valid2, valid3)).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y_DuoEYVJRt"
      },
      "source": [
        "train_well = train.WELL.values\n",
        "train_depth = train.DEPTH_MD.values\n",
        " \n",
        "valid1_well = valid1.WELL.values\n",
        "valid1_depth = valid1.DEPTH_MD.values\n",
        " \n",
        "valid2_well = valid2.WELL.values\n",
        "valid2_depth = valid2.DEPTH_MD.values\n",
        " \n",
        "valid3_well = valid3.WELL.values\n",
        "valid3_depth = valid3.DEPTH_MD.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zMlY-7RZDBq"
      },
      "source": [
        "lithology = train['FORCE_2020_LITHOFACIES_LITHOLOGY']\n",
        "valid1_lithology = valid1['FORCE_2020_LITHOFACIES_LITHOLOGY']\n",
        "valid2_lithology = valid2['FORCE_2020_LITHOFACIES_LITHOLOGY']\n",
        "valid3_lithology = valid3['FORCE_2020_LITHOFACIES_LITHOLOGY']\n",
        " \n",
        "lithology_numbers = {30000: 0,\n",
        "                 65030: 1,\n",
        "                 65000: 2,\n",
        "                 80000: 3,\n",
        "                 74000: 4,\n",
        "                 70000: 5,\n",
        "                 70032: 6,\n",
        "                 88000: 7,\n",
        "                 86000: 8,\n",
        "                 99000: 9,\n",
        "                 90000: 10,\n",
        "                 93000: 11}\n",
        " \n",
        "lithology = lithology.map(lithology_numbers)\n",
        "valid1_lithology = valid1_lithology.map(lithology_numbers)\n",
        "valid2_lithology = valid2_lithology.map(lithology_numbers)\n",
        "valid3_lithology = valid3_lithology.map(lithology_numbers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WI7UomLPx9Cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c3dd86b0-f1e5-4f84-a62a-9e329f1347a6"
      },
      "source": [
        " print(df.shape)\n",
        "cols = ['FORCE_2020_LITHOFACIES_CONFIDENCE', 'SGR', 'DTS', 'RXO', 'ROPA']\n",
        "df = drop_columns(df, *cols)\n",
        "print(df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1512843, 29)\n",
            "(1512843, 24)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRsjiPZqa49_"
      },
      "source": [
        "df['GROUP_encoded'] = df['GROUP'].astype('category')\n",
        "df['GROUP_encoded'] = df['GROUP_encoded'].cat.codes\n",
        "df['FORMATION_encoded'] = df['FORMATION'].astype('category')\n",
        "df['FORMATION_encoded'] = df['FORMATION_encoded'].cat.codes\n",
        "df['WELL_encoded'] = df['WELL'].astype('category')\n",
        "df['WELL_encoded'] = df['WELL_encoded'].cat.codes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mV6wikmIa7Av",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7b5856db-753b-483c-cde5-03f090101b0d"
      },
      "source": [
        "df = df.drop(['WELL', 'GROUP', 'FORMATION'], axis=1)\n",
        "df.shape\n",
        " \n",
        "df = df.fillna(-999)\n",
        "df = process(df)\n",
        "data = df.copy()\n",
        " \n",
        "train2 = data[:ntrain].copy()\n",
        "target = train2.FORCE_2020_LITHOFACIES_LITHOLOGY.copy()\n",
        "validation1_target = valid1.FORCE_2020_LITHOFACIES_LITHOLOGY.copy()\n",
        "validation2_target = valid2.FORCE_2020_LITHOFACIES_LITHOLOGY.copy()\n",
        "train2.drop(['FORCE_2020_LITHOFACIES_LITHOLOGY'], axis=1, inplace=True)\n",
        " \n",
        "test2 = data[ntrain:(ntest+ntrain)].copy()\n",
        "test2.drop(['FORCE_2020_LITHOFACIES_LITHOLOGY'], axis=1, inplace=True)\n",
        "test2 = test2.reset_index(drop=True)\n",
        " \n",
        "validation1 = data[(ntest+ntrain):(ntest+ntrain+nvalid1)].copy()\n",
        "validation1.drop(['FORCE_2020_LITHOFACIES_LITHOLOGY'], axis=1, inplace=True)\n",
        "validation1 = validation1.reset_index(drop=True)\n",
        " \n",
        "validation2 = data[(ntrain+ntest+nvalid1): (ntrain+ntest+nvalid1+nvalid2)].copy()\n",
        "validation2.drop(['FORCE_2020_LITHOFACIES_LITHOLOGY'], axis=1, inplace=True)\n",
        "validation2 = validation2.reset_index(drop=True)\n",
        " \n",
        " \n",
        "validation3 = data[(ntrain+ntest+nvalid1+nvalid2):].copy()\n",
        "validation3.drop(['FORCE_2020_LITHOFACIES_LITHOLOGY'], axis=1, inplace=True)\n",
        "validation3 = validation3.reset_index(drop=True)\n",
        " \n",
        "print(train2.shape, test2.shape, validation1.shape, valid1.shape, validation2.shape, validation3.shape, valid2.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(964965, 23) (136786, 23) (114079, 23) (114079, 29) (91467, 23) (205546, 23) (91467, 29)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTL3T6Dva_X3"
      },
      "source": [
        "traindata = train2\n",
        "testdata = test2\n",
        "from sklearn.preprocessing import StandardScaler\n",
        " \n",
        "scaler = StandardScaler().fit(traindata)\n",
        "def scale_data(data):\n",
        "  \n",
        "  data = scaler.transform(data)\n",
        "  #testdata = scaler.transform(testdata)\n",
        "  data = pd.DataFrame(data, columns=testdata.columns)\n",
        " \n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQzZOwBdU6MJ"
      },
      "source": [
        "traindata, padded_rows = augment_features(traindata.values, train_well, train_depth)\n",
        "validation1, padded_rows1= augment_features(validation1.values, valid1_well, valid1_depth)\n",
        "validation2, padded_rows2 = augment_features(validation2.values, valid2_well, valid2_depth)\n",
        "validation3, padded_rows3 = augment_features(validation3.values, valid3_well, valid3_depth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnLtAk3zTs14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8489fb28-0d80-48c9-baf3-8be3180b3425"
      },
      "source": [
        "traindata.shape, validation1.shape, validation3.shape, validation2.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((964965, 92), (114079, 92), (205546, 92), (91467, 92))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoHq2Qa5bHuL"
      },
      "source": [
        "class Model():\n",
        "    \n",
        "    def __init__(self, train, validation1, validation2, validation3, train_label, valid_label1, valid_label2, valid_label3):\n",
        "        \n",
        "        \n",
        "        self.train = train\n",
        "        #self.test = test\n",
        "        self.validation1 = validation1\n",
        "        self.validation2 = validation2\n",
        "        self.validation3 = validation3\n",
        "        self.train_label = train_label\n",
        "        self.valid_label1 = valid_label1\n",
        "        self.valid_label2 = valid_label2\n",
        "        self.valid_label3 = valid_label3\n",
        "        \n",
        "    def __call__(self, plot = True):\n",
        "        return self.fit(plot)\n",
        "    \n",
        "    def fit(self, plot):\n",
        " \n",
        "      #self.x_train, self.x_test, self.y_train, self.y_test = ms.train_test_split(self.train, \n",
        "                                                                                  # pd.DataFrame(np.array(self.train_label)), \n",
        "                                                                                   #test_size=0.2,\n",
        "                                                                                   #random_state=212)\n",
        "      #self.x_train = self.train.iloc[:700000]\n",
        "      #self.x_test = self.train.iloc[700000:]\n",
        "      #self.y_train = pd.DataFrame(self.train_label).iloc[:700000]\n",
        "      #self.y_test = pd.DataFrame(self.train_label).iloc[700000:]\n",
        "      \n",
        "      def show_evaluation(pred, true):\n",
        "        \n",
        "        print(f'Default score: {score(true.values, pred)}')\n",
        "        print(f'Accuracy is: {accuracy_score(true, pred)}')\n",
        "        print(f'F1 is: {f1_score(pred, true.values, average=\"weighted\")}')\n",
        " \n",
        "      split = 10\n",
        "      kf = StratifiedKFold(n_splits=split, shuffle=False)\n",
        "  \n",
        "      #pred = np.zeros((len(self.test), 12))\n",
        "      val1 = np.zeros((len(self.validation1), 12))\n",
        "      val2 = np.zeros((len(self.validation2), 12))\n",
        "      val3 = np.zeros((len(self.validation3), 12))\n",
        " \n",
        "      #model = CatBoostClassifier(n_estimators=500000, random_state=2020, learning_rate=0.01,\n",
        "                                 #use_best_model=True, max_depth=6, reg_lambda=500,\n",
        "                                 #eval_metric='MultiClass', task_type='GPU', verbose=100)\n",
        " \n",
        "      model = XGBClassifier(n_estimators=50000, max_depth=11, reg_lambda=1500, reg_alpha=500, gamma=500,\n",
        "                            objective='multi:softprob', learning_rate=0.033, colsample_bylevel=0.9,\n",
        "                            subsample=0.9, col_sample_bytree=0.9, tree_method='gpu_hist',\n",
        "                            eval_metric='mlogloss', verbose=2020, colsample_bynode=0.9)\n",
        "      \n",
        "      #model = LGBMClassifier(n_estimators=50000, max_depth=10, reg_lambda=200,\n",
        "                            #objective='multiclass', learning_rate=0.033,\n",
        "                            #eval_metric='multi_logloss')\n",
        "      \n",
        "      #model = RandomForestClassifier(n_estimators=100, class_weight='balanced', verbose=2)\n",
        "      i = 1\n",
        "      for (train_index, test_index) in kf.split(pd.DataFrame(traindata), pd.DataFrame(lithology)):\n",
        "        X_train,X_test = pd.DataFrame(traindata).iloc[train_index], pd.DataFrame(traindata).iloc[test_index]\n",
        "        Y_train,Y_test = pd.DataFrame(lithology).iloc[train_index],pd.DataFrame(lithology).iloc[test_index]\n",
        "    \n",
        "        \n",
        "        model.fit(X_train, Y_train, early_stopping_rounds=100, eval_set=[(X_test, Y_test)], verbose=100)\n",
        "        #model.fit(X_train, Y_train)\n",
        "        prediction1 = model.predict(self.validation1)\n",
        "        prediction = model.predict(self.validation2)\n",
        "        print(show_evaluation(prediction1, self.valid_label1))\n",
        "        print(show_evaluation(prediction, self.valid_label2))\n",
        " \n",
        "        print(f'-----------------------FOLD {i}---------------------')\n",
        "        i+=1\n",
        " \n",
        "        #pred += model.predict_proba(self.test)\n",
        "        val1 += model.predict_proba(self.validation1)\n",
        "        val2 += model.predict_proba(self.validation2)\n",
        "        val3 += model.predict_proba(self.validation3)\n",
        "      \n",
        "      #pred = pd.DataFrame(pred/split)\n",
        "      val1 = pd.DataFrame(val1/split)\n",
        "      val2 = pd.DataFrame(val2/split)\n",
        "      val3 = pd.DataFrame(val3/split)\n",
        "    \n",
        "      #pred = np.array(pd.DataFrame(pred).idxmax(axis=1))\n",
        "      val1 = np.array(pd.DataFrame(val1).idxmax(axis=1))\n",
        "      val2 = np.array(pd.DataFrame(val2).idxmax(axis=1))\n",
        "      val3 = np.array(pd.DataFrame(val3).idxmax(axis=1))\n",
        " \n",
        "      print('---------------CROSS VALIDATION COMPLETE')\n",
        "      print('----------------TEST EVALUATION------------------')\n",
        " \n",
        "      print('----------Valid 1-------------')\n",
        "      print(show_evaluation(val1, self.valid_label1))\n",
        "      print('----------Valid 2-------------')\n",
        "      print(show_evaluation(val2, self.valid_label2))\n",
        "      print('----------Valid 3-------------')\n",
        "      print(show_evaluation(val3, self.valid_label3))\n",
        "                  \n",
        "      if plot: self.plot_feat_imp(model)\n",
        "      return val1, val2, val3, model\n",
        "              \n",
        "              \n",
        "    def plot_feat_imp(self, model):\n",
        "        feat_imp = pd.Series(model.feature_importances_).sort_values(ascending=False)\n",
        "        plt.figure(figsize=(12,8))\n",
        "        feat_imp.plot(kind='bar', title='Feature Importances')\n",
        "        plt.ylabel('Feature Importance Score')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-B7zhV0Yg9Q"
      },
      "source": [
        "class Model():\n",
        "    \n",
        "    def __init__(self, train, validation1, validation2, validation3, train_label, valid_label1, valid_label2, valid_label3):\n",
        "        \n",
        "        \n",
        "        self.train = train\n",
        "        #self.test = test\n",
        "        self.validation1 = validation1\n",
        "        self.validation2 = validation2\n",
        "        self.validation3 = validation3\n",
        "        self.train_label = train_label\n",
        "        self.valid_label1 = valid_label1\n",
        "        self.valid_label2 = valid_label2\n",
        "        self.valid_label3 = valid_label3\n",
        "        \n",
        "    def __call__(self, plot = True):\n",
        "        return self.fit(plot)\n",
        "    \n",
        "    def fit(self, plot):\n",
        " \n",
        "      #self.x_train, self.x_test, self.y_train, self.y_test = ms.train_test_split(self.train, \n",
        "                                                                                  # pd.DataFrame(np.array(self.train_label)), \n",
        "                                                                                   #test_size=0.2,\n",
        "                                                                                   #random_state=212)\n",
        "      #self.x_train = self.train.iloc[:700000]\n",
        "      #self.x_test = self.train.iloc[700000:]\n",
        "      #self.y_train = pd.DataFrame(self.train_label).iloc[:700000]\n",
        "      #self.y_test = pd.DataFrame(self.train_label).iloc[700000:]\n",
        "      \n",
        "      def show_evaluation(pred, true):\n",
        "        \n",
        "        print(f'Default score: {score(true.values, pred)}')\n",
        "        print(f'Accuracy is: {accuracy_score(true, pred)}')\n",
        "        print(f'F1 is: {f1_score(pred, true.values, average=\"weighted\")}')\n",
        " \n",
        "      split = 10\n",
        "      kf = StratifiedKFold(n_splits=split, shuffle=True)\n",
        "  \n",
        "      #pred = np.zeros((len(self.test), 12))\n",
        "      val1 = np.zeros((len(self.validation1), 12))\n",
        "      val2 = np.zeros((len(self.validation2), 12))\n",
        "      val3 = np.zeros((len(self.validation3), 12))\n",
        " \n",
        "      model = CatBoostClassifier(n_estimators=500, learning_rate=0.033,\n",
        "                                 use_best_model=True, max_depth=8, reg_lambda=1500,\n",
        "                                 eval_metric='MultiClass', task_type='GPU', verbose=100)\n",
        " \n",
        "      #model = XGBClassifier(n_estimators=1000, max_depth=11, reg_lambda=1500, booster_type='gbtree',\n",
        "                            #objective='multi:softprob', learning_rate=0.033,\n",
        "                            #subsample=0.9, col_sample_bytree=0.9, tree_method='gpu_hist', \n",
        "                            #eval_metric='mlogloss', verbose=2020)\n",
        "      \n",
        "      #model = LGBMClassifier(n_estimators=50000, max_depth=10, reg_lambda=200,\n",
        "                            #objective='multiclass', learning_rate=0.033,\n",
        "                            #eval_metric='multi_logloss')\n",
        "      \n",
        "      #model = RandomForestClassifier(n_estimators=100, class_weight='balanced', verbose=2)\n",
        "      i = 1\n",
        "      for (train_index, test_index) in kf.split(pd.DataFrame(traindata), pd.DataFrame(lithology)):\n",
        "        X_train,X_test = pd.DataFrame(traindata).iloc[train_index], pd.DataFrame(traindata).iloc[test_index]\n",
        "        Y_train,Y_test = pd.DataFrame(lithology).iloc[train_index],pd.DataFrame(lithology).iloc[test_index]\n",
        "    \n",
        "        \n",
        "        model.fit(X_train, Y_train, early_stopping_rounds=100, eval_set=[(X_test, Y_test)], verbose=100)\n",
        "        #model.fit(X_train, Y_train)\n",
        "        prediction1 = model.predict(pd.DataFrame(self.validation1))\n",
        "        prediction = model.predict(pd.DataFrame(self.validation2))\n",
        "        print(show_evaluation(prediction1, self.valid_label1))\n",
        "        print(show_evaluation(prediction, self.valid_label2))\n",
        " \n",
        "        print(f'-----------------------FOLD {i}---------------------')\n",
        "        i+=1\n",
        " \n",
        "        #pred += model.predict_proba(self.test)\n",
        "        val1 += model.predict_proba(pd.DataFrame(self.validation1))\n",
        "        val2 += model.predict_proba(pd.DataFrame(self.validation2))\n",
        "        val3 += model.predict_proba(pd.DataFrame(self.validation3))\n",
        "      \n",
        "      #pred = pd.DataFrame(pred/split)\n",
        "      val1 = pd.DataFrame(val1/split)\n",
        "      val2 = pd.DataFrame(val2/split)\n",
        "      val3 = pd.DataFrame(val3/split)\n",
        "    \n",
        "      #pred = np.array(pd.DataFrame(pred).idxmax(axis=1))\n",
        "      val1 = np.array(pd.DataFrame(val1).idxmax(axis=1))\n",
        "      val2 = np.array(pd.DataFrame(val2).idxmax(axis=1))\n",
        "      val3 = np.array(pd.DataFrame(val3).idxmax(axis=1))\n",
        " \n",
        "      print('---------------CROSS VALIDATION COMPLETE')\n",
        "      print('----------------TEST EVALUATION------------------')\n",
        " \n",
        "      print('----------Valid 1-------------')\n",
        "      print(show_evaluation(val1, self.valid_label1))\n",
        "      print('----------Valid 2-------------')\n",
        "      print(show_evaluation(val2, self.valid_label2))\n",
        "      print('----------Valid 3-------------')\n",
        "      print(show_evaluation(val3, self.valid_label3))\n",
        "                  \n",
        "      if plot: self.plot_feat_imp(model)\n",
        "      return val1, val2, val3, model\n",
        "              \n",
        "              \n",
        "    def plot_feat_imp(self, model):\n",
        "        feat_imp = pd.Series(model.feature_importances_).sort_values(ascending=False)\n",
        "        plt.figure(figsize=(12,8))\n",
        "        feat_imp.plot(kind='bar', title='Feature Importances')\n",
        "        plt.ylabel('Feature Importance Score')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGxB5ZiD560L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "be4a4923-97ec-4a0c-d5a3-a580b57bdcfd"
      },
      "source": [
        "func1_= Model(traindata, validation1, validation2, validation3, lithology, valid1_lithology, valid2_lithology, valid3_lithology)\n",
        "val1, open_test1, open_test11, model1 = func1_()   #no reglambda, 0.01 lr, 6max-depth (dts, rxo, sgr, ropa)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0:\tlearn: 2.3728927\ttest: 2.3726813\tbest: 2.3726813 (0)\ttotal: 67.7ms\tremaining: 33.8s\n",
            "100:\tlearn: 0.7696968\ttest: 0.7663310\tbest: 0.7663310 (100)\ttotal: 6.35s\tremaining: 25.1s\n",
            "200:\tlearn: 0.6022158\ttest: 0.5995316\tbest: 0.5995316 (200)\ttotal: 12.3s\tremaining: 18.2s\n",
            "300:\tlearn: 0.5430381\ttest: 0.5408642\tbest: 0.5408642 (300)\ttotal: 18.2s\tremaining: 12s\n",
            "400:\tlearn: 0.5114508\ttest: 0.5097472\tbest: 0.5097472 (400)\ttotal: 23.9s\tremaining: 5.89s\n",
            "499:\tlearn: 0.4882004\ttest: 0.4867317\tbest: 0.4867317 (499)\ttotal: 29.4s\tremaining: 0us\n",
            "bestTest = 0.4867316552\n",
            "bestIteration = 499\n",
            "Default score: [-0.75468097]\n",
            "Accuracy is: 0.713926314220847\n",
            "F1 is: 0.7320726655512828\n",
            "None\n",
            "Default score: [-0.59506161]\n",
            "Accuracy is: 0.7797784993494922\n",
            "F1 is: 0.8139235277621336\n",
            "None\n",
            "-----------------------FOLD 1---------------------\n",
            "0:\tlearn: 2.3732203\ttest: 2.3731946\tbest: 2.3731946 (0)\ttotal: 69.6ms\tremaining: 34.7s\n",
            "100:\tlearn: 0.7701419\ttest: 0.7645077\tbest: 0.7645077 (100)\ttotal: 6.43s\tremaining: 25.4s\n",
            "200:\tlearn: 0.6028213\ttest: 0.5966463\tbest: 0.5966463 (200)\ttotal: 12.3s\tremaining: 18.3s\n",
            "300:\tlearn: 0.5436717\ttest: 0.5375087\tbest: 0.5375087 (300)\ttotal: 18.2s\tremaining: 12s\n",
            "400:\tlearn: 0.5104049\ttest: 0.5044827\tbest: 0.5044827 (400)\ttotal: 23.8s\tremaining: 5.87s\n",
            "499:\tlearn: 0.4883129\ttest: 0.4824225\tbest: 0.4824225 (499)\ttotal: 29.4s\tremaining: 0us\n",
            "bestTest = 0.4824225024\n",
            "bestIteration = 499\n",
            "Default score: [-0.73393986]\n",
            "Accuracy is: 0.718133924736367\n",
            "F1 is: 0.735168415610455\n",
            "None\n",
            "Default score: [-0.59568478]\n",
            "Accuracy is: 0.7797129019209114\n",
            "F1 is: 0.8142513628893217\n",
            "None\n",
            "-----------------------FOLD 2---------------------\n",
            "0:\tlearn: 2.3727634\ttest: 2.3729949\tbest: 2.3729949 (0)\ttotal: 63.5ms\tremaining: 31.7s\n",
            "100:\tlearn: 0.7644730\ttest: 0.7648964\tbest: 0.7648964 (100)\ttotal: 6.29s\tremaining: 24.9s\n",
            "200:\tlearn: 0.6027593\ttest: 0.6034102\tbest: 0.6034102 (200)\ttotal: 12.2s\tremaining: 18.2s\n",
            "300:\tlearn: 0.5431324\ttest: 0.5438824\tbest: 0.5438824 (300)\ttotal: 18s\tremaining: 11.9s\n",
            "400:\tlearn: 0.5090990\ttest: 0.5099638\tbest: 0.5099638 (400)\ttotal: 23.7s\tremaining: 5.85s\n",
            "499:\tlearn: 0.4872121\ttest: 0.4881500\tbest: 0.4881500 (499)\ttotal: 29.1s\tremaining: 0us\n",
            "bestTest = 0.4881499716\n",
            "bestIteration = 499\n",
            "Default score: [-0.72793634]\n",
            "Accuracy is: 0.7230252719606588\n",
            "F1 is: 0.7414265678905281\n",
            "None\n",
            "Default score: [-0.59754884]\n",
            "Accuracy is: 0.7793083844446631\n",
            "F1 is: 0.8102022777475152\n",
            "None\n",
            "-----------------------FOLD 3---------------------\n",
            "0:\tlearn: 2.3729068\ttest: 2.3730940\tbest: 2.3730940 (0)\ttotal: 67.9ms\tremaining: 33.9s\n",
            "100:\tlearn: 0.7687885\ttest: 0.7701508\tbest: 0.7701508 (100)\ttotal: 6.38s\tremaining: 25.2s\n",
            "200:\tlearn: 0.6030992\ttest: 0.6047556\tbest: 0.6047556 (200)\ttotal: 12.3s\tremaining: 18.3s\n",
            "400:\tlearn: 0.5095926\ttest: 0.5113283\tbest: 0.5113283 (400)\ttotal: 23.6s\tremaining: 5.83s\n",
            "499:\tlearn: 0.4856245\ttest: 0.4873803\tbest: 0.4873803 (499)\ttotal: 29.1s\tremaining: 0us\n",
            "bestTest = 0.4873802748\n",
            "bestIteration = 499\n",
            "Default score: [-0.70373601]\n",
            "Accuracy is: 0.7310022002296654\n",
            "F1 is: 0.7534402112756521\n",
            "None\n",
            "Default score: [-0.5987173]\n",
            "Accuracy is: 0.7780729662063913\n",
            "F1 is: 0.8121668903549133\n",
            "None\n",
            "-----------------------FOLD 4---------------------\n",
            "0:\tlearn: 2.3726577\ttest: 2.3726337\tbest: 2.3726337 (0)\ttotal: 64.4ms\tremaining: 32.1s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-b6c5d12294da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfunc1_\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraindata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlithology\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid1_lithology\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid2_lithology\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid3_lithology\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mval1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen_test1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen_test11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc1_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m#no reglambda, 0.01 lr, 6max-depth (dts, rxo, sgr, ropa)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-5101ef86e5a7>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, plot)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-5101ef86e5a7>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, plot)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;31m#model.fit(X_train, Y_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mprediction1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[1;32m   4296\u001b[0m         self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001b[1;32m   4297\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4298\u001b[0;31m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\n\u001b[0m\u001b[1;32m   4299\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[1;32m   1807\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1808\u001b[0m                 \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1809\u001b[0;31m                 \u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"init_model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1810\u001b[0m             )\n\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1258\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1259\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ9CT9TbXRhD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ea5c645b-e77e-4b1e-a38f-95333e4a35a0"
      },
      "source": [
        "func1_= Model(traindata, validation1, validation2, validation3, lithology, valid1_lithology, valid2_lithology, valid3_lithology)\n",
        "val1, open_test1, open_test11, model1 = func1_()   #no reglambda, 0.01 lr, 6max-depth (dts, rxo, sgr, ropa)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0:\tlearn: 2.4025523\ttest: 2.4552740\tbest: 2.4552740 (0)\ttotal: 302ms\tremaining: 4h 11m 30s\n",
            "100:\tlearn: 0.8624995\ttest: 1.5903336\tbest: 1.5903336 (100)\ttotal: 22.3s\tremaining: 3h 3m 39s\n",
            "200:\tlearn: 0.6177713\ttest: 1.4078229\tbest: 1.4078229 (200)\ttotal: 43.8s\tremaining: 3h 59s\n",
            "300:\tlearn: 0.5195834\ttest: 1.3705727\tbest: 1.3652614 (254)\ttotal: 1m 3s\tremaining: 2h 55m 38s\n",
            "bestTest = 1.365261355\n",
            "bestIteration = 254\n",
            "Shrink model to first 255 iterations.\n",
            "Default score: [-0.76779907]\n",
            "Accuracy is: 0.714189289878067\n",
            "F1 is: 0.7446878302880734\n",
            "None\n",
            "Default score: [-0.60574852]\n",
            "Accuracy is: 0.7729345009675621\n",
            "F1 is: 0.8143156381894381\n",
            "None\n",
            "-----------------------FOLD 1---------------------\n",
            "0:\tlearn: 2.4155061\ttest: 2.4159041\tbest: 2.4159041 (0)\ttotal: 315ms\tremaining: 4h 22m 10s\n",
            "100:\tlearn: 0.8545950\ttest: 1.3988379\tbest: 1.3985574 (99)\ttotal: 22.6s\tremaining: 3h 5m 54s\n",
            "200:\tlearn: 0.6300971\ttest: 1.3567600\tbest: 1.3533327 (197)\ttotal: 45.2s\tremaining: 3h 6m 50s\n",
            "300:\tlearn: 0.5215040\ttest: 1.3172569\tbest: 1.3134119 (284)\ttotal: 1m 6s\tremaining: 3h 1m 55s\n",
            "bestTest = 1.313411945\n",
            "bestIteration = 284\n",
            "Shrink model to first 285 iterations.\n",
            "Default score: [-0.75665328]\n",
            "Accuracy is: 0.714662646061063\n",
            "F1 is: 0.7387864355191837\n",
            "None\n",
            "Default score: [-0.68908322]\n",
            "Accuracy is: 0.7544250932030131\n",
            "F1 is: 0.7882681853829825\n",
            "None\n",
            "-----------------------FOLD 2---------------------\n",
            "0:\tlearn: 2.4287579\ttest: 2.4370610\tbest: 2.4370610 (0)\ttotal: 317ms\tremaining: 4h 24m 26s\n",
            "100:\tlearn: 0.8767686\ttest: 1.5955911\tbest: 1.5941268 (99)\ttotal: 23s\tremaining: 3h 9m 22s\n",
            "200:\tlearn: 0.6450240\ttest: 1.5450302\tbest: 1.5431471 (194)\ttotal: 46.2s\tremaining: 3h 10m 45s\n",
            "300:\tlearn: 0.5302831\ttest: 1.5162892\tbest: 1.5137776 (294)\ttotal: 1m 7s\tremaining: 3h 5m 46s\n",
            "400:\tlearn: 0.4769566\ttest: 1.5712274\tbest: 1.5111517 (322)\ttotal: 1m 28s\tremaining: 3h 3m 13s\n",
            "bestTest = 1.511151739\n",
            "bestIteration = 322\n",
            "Shrink model to first 323 iterations.\n",
            "Default score: [-0.7241988]\n",
            "Accuracy is: 0.7266017408988508\n",
            "F1 is: 0.7576901100274918\n",
            "None\n",
            "Default score: [-0.56224923]\n",
            "Accuracy is: 0.7881968360173615\n",
            "F1 is: 0.8180582119211147\n",
            "None\n",
            "-----------------------FOLD 3---------------------\n",
            "0:\tlearn: 2.4192555\ttest: 2.4547832\tbest: 2.4547832 (0)\ttotal: 328ms\tremaining: 4h 33m 6s\n",
            "100:\tlearn: 0.8741948\ttest: 1.6131117\tbest: 1.6131117 (100)\ttotal: 23.4s\tremaining: 3h 12m 19s\n",
            "200:\tlearn: 0.6383354\ttest: 1.4846644\tbest: 1.4843648 (199)\ttotal: 46.1s\tremaining: 3h 10m 14s\n",
            "300:\tlearn: 0.5348803\ttest: 1.4233793\tbest: 1.4233793 (300)\ttotal: 1m 7s\tremaining: 3h 5m 50s\n",
            "400:\tlearn: 0.4826083\ttest: 1.4107539\tbest: 1.4101021 (393)\ttotal: 1m 29s\tremaining: 3h 3m 36s\n",
            "500:\tlearn: 0.4521363\ttest: 1.3991534\tbest: 1.3988804 (482)\ttotal: 1m 50s\tremaining: 3h 1m 46s\n",
            "600:\tlearn: 0.4314013\ttest: 1.4013517\tbest: 1.3929714 (530)\ttotal: 2m 10s\tremaining: 2h 59m 25s\n",
            "bestTest = 1.392971414\n",
            "bestIteration = 530\n",
            "Shrink model to first 531 iterations.\n",
            "Default score: [-0.80170649]\n",
            "Accuracy is: 0.7023115560269638\n",
            "F1 is: 0.7168811371519923\n",
            "None\n",
            "Default score: [-0.6114719]\n",
            "Accuracy is: 0.772464386062733\n",
            "F1 is: 0.7965608837886073\n",
            "None\n",
            "-----------------------FOLD 4---------------------\n",
            "0:\tlearn: 2.4172454\ttest: 2.4376844\tbest: 2.4376844 (0)\ttotal: 302ms\tremaining: 4h 11m 40s\n",
            "100:\tlearn: 0.8947033\ttest: 1.6289836\tbest: 1.6289836 (100)\ttotal: 23.6s\tremaining: 3h 14m 3s\n",
            "200:\tlearn: 0.6488608\ttest: 1.5161917\tbest: 1.5161917 (200)\ttotal: 47s\tremaining: 3h 14m 15s\n",
            "300:\tlearn: 0.5430497\ttest: 1.4463678\tbest: 1.4463678 (300)\ttotal: 1m 8s\tremaining: 3h 9m 48s\n",
            "400:\tlearn: 0.4842622\ttest: 1.4313188\tbest: 1.4280313 (355)\ttotal: 1m 30s\tremaining: 3h 6m\n",
            "500:\tlearn: 0.4526885\ttest: 1.4322455\tbest: 1.4255919 (447)\ttotal: 1m 52s\tremaining: 3h 4m 34s\n",
            "bestTest = 1.425591923\n",
            "bestIteration = 447\n",
            "Shrink model to first 448 iterations.\n",
            "Default score: [-0.76922242]\n",
            "Accuracy is: 0.7059932152280437\n",
            "F1 is: 0.7173349220114967\n",
            "None\n",
            "Default score: [-0.56465583]\n",
            "Accuracy is: 0.7900335640176238\n",
            "F1 is: 0.819030851472741\n",
            "None\n",
            "-----------------------FOLD 5---------------------\n",
            "0:\tlearn: 2.3924304\ttest: 2.4331734\tbest: 2.4331734 (0)\ttotal: 314ms\tremaining: 4h 21m 57s\n",
            "100:\tlearn: 0.8554670\ttest: 1.6086258\tbest: 1.6086258 (100)\ttotal: 22.5s\tremaining: 3h 5m 15s\n",
            "200:\tlearn: 0.6408831\ttest: 1.5325418\tbest: 1.5314312 (196)\ttotal: 44.6s\tremaining: 3h 4m 10s\n",
            "300:\tlearn: 0.5427361\ttest: 1.5117649\tbest: 1.5108055 (298)\ttotal: 1m 5s\tremaining: 3h 1m 32s\n",
            "400:\tlearn: 0.4913168\ttest: 1.4707872\tbest: 1.4707872 (400)\ttotal: 1m 26s\tremaining: 2h 58m 51s\n",
            "500:\tlearn: 0.4598345\ttest: 1.4469139\tbest: 1.4460110 (462)\ttotal: 1m 47s\tremaining: 2h 56m 30s\n",
            "600:\tlearn: 0.4395429\ttest: 1.4478199\tbest: 1.4451237 (509)\ttotal: 2m 7s\tremaining: 2h 55m 11s\n",
            "bestTest = 1.445123697\n",
            "bestIteration = 509\n",
            "Shrink model to first 510 iterations.\n",
            "Default score: [-0.7094634]\n",
            "Accuracy is: 0.7318963174642134\n",
            "F1 is: 0.7568543540325692\n",
            "None\n",
            "Default score: [-0.60989756]\n",
            "Accuracy is: 0.769348508205145\n",
            "F1 is: 0.7807704529948212\n",
            "None\n",
            "-----------------------FOLD 6---------------------\n",
            "0:\tlearn: 2.4316248\ttest: 2.4697369\tbest: 2.4697369 (0)\ttotal: 344ms\tremaining: 4h 46m 26s\n",
            "100:\tlearn: 0.9005934\ttest: 1.8165274\tbest: 1.8165274 (100)\ttotal: 23s\tremaining: 3h 9m 12s\n",
            "200:\tlearn: 0.6627391\ttest: 1.7130232\tbest: 1.7130232 (200)\ttotal: 46.3s\tremaining: 3h 11m 15s\n",
            "300:\tlearn: 0.5460329\ttest: 1.6255659\tbest: 1.6255659 (300)\ttotal: 1m 7s\tremaining: 3h 7m 1s\n",
            "400:\tlearn: 0.4866515\ttest: 1.6014564\tbest: 1.6009237 (389)\ttotal: 1m 28s\tremaining: 3h 2m 54s\n",
            "500:\tlearn: 0.4538633\ttest: 1.6099516\tbest: 1.5995137 (412)\ttotal: 1m 49s\tremaining: 3h 45s\n",
            "bestTest = 1.599513678\n",
            "bestIteration = 412\n",
            "Shrink model to first 413 iterations.\n",
            "Default score: [-0.76608206]\n",
            "Accuracy is: 0.7093154743642563\n",
            "F1 is: 0.7265229666425795\n",
            "None\n",
            "Default score: [-0.67142248]\n",
            "Accuracy is: 0.7469579192495654\n",
            "F1 is: 0.772327764042816\n",
            "None\n",
            "-----------------------FOLD 7---------------------\n",
            "0:\tlearn: 2.4236118\ttest: 2.4535922\tbest: 2.4535922 (0)\ttotal: 332ms\tremaining: 4h 36m 18s\n",
            "100:\tlearn: 0.8599939\ttest: 1.5820717\tbest: 1.5820717 (100)\ttotal: 22.7s\tremaining: 3h 6m 36s\n",
            "200:\tlearn: 0.6307285\ttest: 1.4458179\tbest: 1.4458179 (200)\ttotal: 45.7s\tremaining: 3h 8m 54s\n",
            "300:\tlearn: 0.5258773\ttest: 1.3814480\tbest: 1.3802039 (295)\ttotal: 1m 6s\tremaining: 3h 3m 51s\n",
            "400:\tlearn: 0.4696657\ttest: 1.3554177\tbest: 1.3487450 (363)\ttotal: 1m 27s\tremaining: 3h 28s\n",
            "bestTest = 1.348745026\n",
            "bestIteration = 363\n",
            "Shrink model to first 364 iterations.\n",
            "Default score: [-0.68829057]\n",
            "Accuracy is: 0.7427309145416773\n",
            "F1 is: 0.773129209651049\n",
            "None\n",
            "Default score: [-0.64059442]\n",
            "Accuracy is: 0.7680256267287656\n",
            "F1 is: 0.8057438843677394\n",
            "None\n",
            "-----------------------FOLD 8---------------------\n",
            "0:\tlearn: 2.4307888\ttest: 2.4621610\tbest: 2.4621610 (0)\ttotal: 326ms\tremaining: 4h 31m 52s\n",
            "100:\tlearn: 0.8543705\ttest: 1.5793546\tbest: 1.5793546 (100)\ttotal: 22.7s\tremaining: 3h 6m 58s\n",
            "200:\tlearn: 0.6298592\ttest: 1.4747279\tbest: 1.4747279 (200)\ttotal: 45s\tremaining: 3h 5m 53s\n",
            "300:\tlearn: 0.5276641\ttest: 1.4542083\tbest: 1.4526512 (298)\ttotal: 1m 6s\tremaining: 3h 4m 22s\n",
            "400:\tlearn: 0.4720651\ttest: 1.4485341\tbest: 1.4474879 (328)\ttotal: 1m 28s\tremaining: 3h 2m 16s\n",
            "500:\tlearn: 0.4412837\ttest: 1.4440076\tbest: 1.4435221 (486)\ttotal: 1m 49s\tremaining: 3h 59s\n",
            "600:\tlearn: 0.4182728\ttest: 1.4641664\tbest: 1.4425285 (502)\ttotal: 2m 10s\tremaining: 2h 58m 48s\n",
            "bestTest = 1.442528544\n",
            "bestIteration = 502\n",
            "Shrink model to first 503 iterations.\n",
            "Default score: [-0.74967895]\n",
            "Accuracy is: 0.7145486899429343\n",
            "F1 is: 0.7369206277041639\n",
            "None\n",
            "Default score: [-0.61582046]\n",
            "Accuracy is: 0.7738747307772202\n",
            "F1 is: 0.8040863953009932\n",
            "None\n",
            "-----------------------FOLD 9---------------------\n",
            "0:\tlearn: 2.4095453\ttest: 2.4263091\tbest: 2.4263091 (0)\ttotal: 310ms\tremaining: 4h 18m 20s\n",
            "100:\tlearn: 0.8256665\ttest: 1.3626855\tbest: 1.3626855 (100)\ttotal: 21.8s\tremaining: 2h 59m 36s\n",
            "200:\tlearn: 0.6153613\ttest: 1.1705796\tbest: 1.1705796 (200)\ttotal: 44.2s\tremaining: 3h 2m 39s\n",
            "300:\tlearn: 0.5189773\ttest: 1.0904511\tbest: 1.0904511 (300)\ttotal: 1m 4s\tremaining: 2h 57m 3s\n",
            "400:\tlearn: 0.4725343\ttest: 1.0406953\tbest: 1.0406953 (400)\ttotal: 1m 24s\tremaining: 2h 54m 50s\n",
            "500:\tlearn: 0.4449278\ttest: 1.0200090\tbest: 1.0200090 (500)\ttotal: 1m 45s\tremaining: 2h 53m 25s\n",
            "600:\tlearn: 0.4229000\ttest: 0.9995959\tbest: 0.9995959 (600)\ttotal: 2m 5s\tremaining: 2h 51m 29s\n",
            "700:\tlearn: 0.4067930\ttest: 0.9825745\tbest: 0.9825745 (700)\ttotal: 2m 24s\tremaining: 2h 49m 6s\n",
            "800:\tlearn: 0.3951253\ttest: 0.9731252\tbest: 0.9731252 (800)\ttotal: 2m 43s\tremaining: 2h 47m 7s\n",
            "900:\tlearn: 0.3856267\ttest: 0.9619878\tbest: 0.9619878 (900)\ttotal: 3m 1s\tremaining: 2h 45m 16s\n",
            "1000:\tlearn: 0.3774043\ttest: 0.9536817\tbest: 0.9536817 (1000)\ttotal: 3m 21s\tremaining: 2h 43m 59s\n",
            "1100:\tlearn: 0.3699927\ttest: 0.9475895\tbest: 0.9475895 (1100)\ttotal: 3m 40s\tremaining: 2h 43m 16s\n",
            "1200:\tlearn: 0.3635620\ttest: 0.9433661\tbest: 0.9433661 (1200)\ttotal: 3m 59s\tremaining: 2h 42m 27s\n",
            "1300:\tlearn: 0.3573621\ttest: 0.9407114\tbest: 0.9406983 (1297)\ttotal: 4m 19s\tremaining: 2h 41m 46s\n",
            "1400:\tlearn: 0.3511800\ttest: 0.9409629\tbest: 0.9406348 (1333)\ttotal: 4m 39s\tremaining: 2h 41m 25s\n",
            "1500:\tlearn: 0.3456923\ttest: 0.9408866\tbest: 0.9403210 (1423)\ttotal: 4m 59s\tremaining: 2h 41m 7s\n",
            "1600:\tlearn: 0.3404333\ttest: 0.9395793\tbest: 0.9394909 (1597)\ttotal: 5m 19s\tremaining: 2h 40m 47s\n",
            "1700:\tlearn: 0.3355778\ttest: 0.9398693\tbest: 0.9393288 (1632)\ttotal: 5m 39s\tremaining: 2h 40m 38s\n",
            "bestTest = 0.9393287675\n",
            "bestIteration = 1632\n",
            "Shrink model to first 1633 iterations.\n",
            "Default score: [-0.74497278]\n",
            "Accuracy is: 0.7226921694615135\n",
            "F1 is: 0.7308096566059789\n",
            "None\n",
            "Default score: [-0.56081565]\n",
            "Accuracy is: 0.788513890255502\n",
            "F1 is: 0.8110623238082965\n",
            "None\n",
            "-----------------------FOLD 10---------------------\n",
            "---------------CROSS VALIDATION COMPLETE\n",
            "----------------TEST EVALUATION------------------\n",
            "----------Valid 1-------------\n",
            "Default score: -0.6790919012263431\n",
            "Accuracy is: 0.7428273389493246\n",
            "F1 is: 0.7692025625659241\n",
            "None\n",
            "----------Valid 2-------------\n",
            "Default score: -0.5707290607541518\n",
            "Accuracy is: 0.7879344463030382\n",
            "F1 is: 0.8202442979532678\n",
            "None\n",
            "----------Valid 3-------------\n",
            "Default score: -0.6308709485954482\n",
            "Accuracy is: 0.7628997888550495\n",
            "F1 is: 0.7916565506140861\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dn8Zfr7hbHdm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "650c15db-d26d-4e87-e6c0-670e64c670f8"
      },
      "source": [
        "make_submission(open_test1, 'open_test1_pred1')\n",
        " \n",
        "a = pd.read_csv('/content/drive/My Drive/FORCE-Lithology-Prediction/open_test1_pred1.csv')\n",
        " \n",
        "a['# lithology'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65000    72937\n",
              "30000    10735\n",
              "70000     3704\n",
              "65030     1796\n",
              "99000     1403\n",
              "80000      889\n",
              "90000        3\n",
              "Name: # lithology, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ch1g3urJLAZY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "f6620162-3eab-4b45-c061-7e7d5882ffb4"
      },
      "source": [
        "valid2.FORCE_2020_LITHOFACIES_LITHOLOGY.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65000    62703\n",
              "30000    11898\n",
              "65030     7990\n",
              "70000     4217\n",
              "80000     2635\n",
              "99000     1337\n",
              "90000      531\n",
              "70032      112\n",
              "74000       44\n",
              "Name: FORCE_2020_LITHOFACIES_LITHOLOGY, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hmk07N_T8rHU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "c4d49b82-06fb-4695-b37d-cd1446c75d6e"
      },
      "source": [
        "print(show_evaluation(val1,valid1_lithology))\n",
        "print(show_evaluation(open_test1, valid2_lithology))\n",
        "print(show_evaluation(open_test11, valid3_lithology))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Default score: -0.6287890409277781\n",
            "Accuracy is: 0.7649523575767669\n",
            "F1 is: 0.8072991891979571\n",
            "None\n",
            "Default score: -0.5854133184645829\n",
            "Accuracy is: 0.785398012397914\n",
            "F1 is: 0.8225863227488472\n",
            "None\n",
            "Default score: -0.6094870491276891\n",
            "Accuracy is: 0.7740505774863048\n",
            "F1 is: 0.8132635081176378\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}